{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema de Estudo:** Deteção de Reviews Spam em Produtos de Moda e Acessórios na Amazon.\n",
    "\n",
    "Pretende-se que seja implementada uma solução computacional para estudo e análise de dados em larga escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextualização do problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, pretende-se desenvolver e implementar um modelo computacional capaz de identificar reviews de produtos da categoria \"Clothing, Shoes, and Jewelry\" na Amazon como spam ou não spam. O objetivo é diferenciar reviews genuínas de tentativas de manipulação através de avaliações falsas que podem enganar consumidores e distorcer a percepção do produto. Este problema é particularmente desafiador devido à subjetividade e variabilidade do texto das reviews, bem como às diferentes motivações por trás das reviews spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/01 03:44:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Criar uma sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Clothing_Shoes_and_Jewelry_Analysis\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Caminho para o arquivo JSON\n",
    "file_path = \"Clothing_Shoes_and_Jewelry.json\"\n",
    "\n",
    "# Carregar o dataset\n",
    "df = spark.read.json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|                 _id|      asin|            category|class|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  0.0| [0, 1]|    1.0|My 3-yr-old daugh...|03 21, 2013| A19PBP93OF896|Alinna Satake \"Ca...|Tiny and Poorly C...|    1363824000|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|This was a really...|05 26, 2012|A2G0LNLN79Q6HR|       aj_18 \"Aj_18\"|Really Cute but r...|    1337990400|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Perfect red tutu ...| 11 4, 2013|A2XVJBSRI3SWDI|             abigail|           Nice tutu|    1383523200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Bought it for my ...|01 23, 2014|A1P0IHU93EF9ZK|              Amanda|           i love it|    1390435200|\n",
      "|{5a132293741a2384...|0000031887|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|This is a great t...|02 12, 2011|A1KLRMWW2FWPL4|Amazon Customer \"...|Great tutu-  not ...|    1297468800|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar as primeiras 5 linhas do dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- $oid: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- class: double (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver a estrutura dos dados\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5504331"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o número de linhas do dataframe\n",
    "rows = df.count()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar o número de colunas do dataframe\n",
    "cols = len(df.columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'asin',\n",
       " 'category',\n",
       " 'class',\n",
       " 'helpful',\n",
       " 'overall',\n",
       " 'reviewText',\n",
       " 'reviewTime',\n",
       " 'reviewerID',\n",
       " 'reviewerName',\n",
       " 'summary',\n",
       " 'unixReviewTime']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas do dataframe\n",
    "cols = df.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'_id':** Identificador único de cada review\n",
    "\n",
    "**'asin':** Amazon Standard Identification Number, que é um identificador único para produtos na plataforma da Amazon\n",
    "\n",
    "**'category':** Categoria do produto da review, que indica a que segmento do mercado o produto pertence, como roupas, sapatos ou joias\n",
    "\n",
    "**'class':** Distingue reviews como spam (1.0) ou não spam (0.0)\n",
    "\n",
    "**'helpful':** Array que contém dois números, onde o primeiro indica quantas pessoas acharam a review útil e o segundo quantas pessoas votaram na utilidade da review\n",
    "\n",
    "**'overall':** Nota geral dada ao produto pelo usuário\n",
    "\n",
    "**'reviewText':** Texto completo da review escrita pelo usuário\n",
    "\n",
    "**'reviewTime':** Data em que a review foi publicada\n",
    "\n",
    "**'reviewerID':** Identificador único da pessoa que escreveu a avaliação\n",
    "\n",
    "**'reviewerName':** Nome ou pseudonimo do revisor, conforme apresentado na Amazon no momento da review\n",
    "\n",
    "**'summary':** Resumo da review, que é uma breve descrição ou título que foi dada na avaliação\n",
    "\n",
    "**'unixReviewTime':** Representação em timestamp UNIX da data de publicação da review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================>                  (16 + 8) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+-----+-------+-------+----------+----------+----------+------------+-------+--------------+\n",
      "|_id|asin|category|class|helpful|overall|reviewText|reviewTime|reviewerID|reviewerName|summary|unixReviewTime|\n",
      "+---+----+--------+-----+-------+-------+----------+----------+----------+------------+-------+--------------+\n",
      "|  0|   0|       0|    0|      0|      0|         0|         0|         0|       13180|      0|             0|\n",
      "+---+----+--------+-----+-------+-------+----------+----------+----------+------------+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Verificar os NA\n",
    "from pyspark.sql.functions import col, isnull, when, count\n",
    "\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Limpeza: duplicados, valores ausente\n",
    "- Transformação dos dados: normalizar o texto (remover pontuações, passar o texto para minusculas, ...), converter a data da review para formato timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Limpeza dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:======================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|                 _id|      asin|            category|class|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|{5a13229b741a2384...|B0008EOEPK|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Lee straight leg,...| 01 1, 2014|A2HJ1VX57R6M6L|         Smiling Bob|     Excellent Jeans|    1388534400|\n",
      "|{5a132298741a2384...|B00075ZYRW|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Fits 3x. After wa...| 01 1, 2014|A3VTTTYIB5BANY|           fabfamily|liked them. order...|    1388534400|\n",
      "|{5a132296741a2384...|B00023JSDA|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|The quality/workm...|01 10, 2007|A3TTYJYJJ2Q5TA| Vicki H. \"CA_Vicki\"|     Garnet Necklace|    1168387200|\n",
      "|{5a132298741a2384...|B0006H0PLG|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|These are perfect...|01 10, 2013|A291VG071KOJLQ|Kara E. Henson Ol...|Perfect comfy fit...|    1357776000|\n",
      "|{5a132294741a2384...|B0000BX8L1|Clothing_Shoes_an...|  1.0| [0, 1]|    5.0|I bought two of t...|01 10, 2013|A2GJHM6USEHK2V|    Angela M. Zirkle|A Perfect First W...|    1357776000|\n",
      "|{5a132296741a2384...|B00020J0ZE|Clothing_Shoes_an...|  1.0| [2, 2]|    5.0|I had this watch ...|01 10, 2013| AFC3G5HP17TMV| Stanislav Oygenblik|Excelent watch fo...|    1357776000|\n",
      "|{5a132296741a2384...|B0002A82A8|Clothing_Shoes_an...|  0.0| [0, 0]|    3.0|I bought these be...|01 10, 2013| AY14J85KT6QPX|         tree hugger|sturdy but too he...|    1357776000|\n",
      "|{5a13229a741a2384...|B0007YXRTA|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|I have worn this ...|01 10, 2014|A1IHU2EHU673HE|     Maryanna Foster| Loving my new bra's|    1389312000|\n",
      "|{5a132296741a2384...|B0002M9DQS|Clothing_Shoes_an...|  0.0| [0, 0]|    2.0|I run in 9.5 Asic...|01 10, 2014|A1ZCGBAOW0OC7R|               Ack44|Didn't work for m...|    1389312000|\n",
      "|{5a132299741a2384...|B0007MG03M|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|We ordered the Wa...|01 10, 2014|  AYL3IMY560GR|            Joan Lee|Excited about our...|    1389312000|\n",
      "|{5a132299741a2384...|B0007L44CC|Clothing_Shoes_an...|  1.0| [1, 1]|    5.0|I have owned my C...|01 11, 2007|A117RNBA4YM5Z9|              Skully|Citizen Eco-Drive...|    1168473600|\n",
      "|{5a132294741a2384...|B0000AS4S8|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|This was a gift a...|01 11, 2007|A24H2MZ0QMK595|   Abelina M. Corder|Very nice for the...|    1168473600|\n",
      "|{5a132294741a2384...|B0000AOXKJ|Clothing_Shoes_an...|  1.0| [2, 2]|    5.0|Gave these very p...|01 11, 2007| ABRZR68B3GVUR|          T. Skinner|           Beautiful|    1168473600|\n",
      "|{5a132294741a2384...|B0000AUYUZ|Clothing_Shoes_an...|  1.0| [4, 4]|    5.0|This is the secon...|01 11, 2011|A1X8ORE50J0QZO|Lorraine Curtis \"...|             stylish|    1294704000|\n",
      "|{5a132297741a2384...|B0002QTQA2|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|These boots fit g...|01 11, 2013|A1QF0ZLOAS8LII|              mpac89|     excellent boots|    1357862400|\n",
      "|{5a132299741a2384...|B0007MG03M|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|The seams along t...|01 11, 2013|A27KWOU40GOYG3|          forealisme|A couple of probl...|    1357862400|\n",
      "|{5a132299741a2384...|B0007M6DP2|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Bought these back...|01 11, 2013|A2MNBCNDIRSCYB|           jmsbond76|    Love these shoes|    1357862400|\n",
      "|{5a132296741a2384...|B0002C81BQ|Clothing_Shoes_an...|  1.0| [1, 1]|    5.0|I had always assu...|01 12, 2007| A6CVO2D493P3V|   Barbara L. Stacey|Beautiful Freshwa...|    1168560000|\n",
      "|{5a132294741a2384...|B0000VIGLO|Clothing_Shoes_an...|  1.0| [3, 3]|    4.0|For what I paid, ...|01 12, 2008|A2W9C84H8B2BI8|        Amazon Woman|                Fine|    1200096000|\n",
      "|{5a13229c741a2384...|B0009OP1OW|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Way worth the mon...|01 12, 2009| APOK63WCDK5L5|A. Vaughan \"free ...|            good buy|    1231718400|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remover os duplicados recorrendo ao método dropDuplicates\n",
    "df = df.dropDuplicates()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/abhilashsampath/amazon-review-spam-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|                 _id|      asin|            category|class|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|5a13229b741a2384e...|B0008EOEPK|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Lee straight leg,...| 01 1, 2014|A2HJ1VX57R6M6L|         Smiling Bob|     Excellent Jeans|    1388534400|\n",
      "|5a132298741a2384e...|B00075ZYRW|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|Fits 3x. After wa...| 01 1, 2014|A3VTTTYIB5BANY|           fabfamily|liked them. order...|    1388534400|\n",
      "|5a132296741a2384e...|B00023JSDA|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|The quality/workm...|01 10, 2007|A3TTYJYJJ2Q5TA| Vicki H. \"CA_Vicki\"|     Garnet Necklace|    1168387200|\n",
      "|5a132298741a2384e...|B0006H0PLG|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|These are perfect...|01 10, 2013|A291VG071KOJLQ|Kara E. Henson Ol...|Perfect comfy fit...|    1357776000|\n",
      "|5a132294741a2384e...|B0000BX8L1|Clothing_Shoes_an...|  1.0| [0, 1]|    5.0|I bought two of t...|01 10, 2013|A2GJHM6USEHK2V|    Angela M. Zirkle|A Perfect First W...|    1357776000|\n",
      "|5a132296741a2384e...|B00020J0ZE|Clothing_Shoes_an...|  1.0| [2, 2]|    5.0|I had this watch ...|01 10, 2013| AFC3G5HP17TMV| Stanislav Oygenblik|Excelent watch fo...|    1357776000|\n",
      "|5a132296741a2384e...|B0002A82A8|Clothing_Shoes_an...|  0.0| [0, 0]|    3.0|I bought these be...|01 10, 2013| AY14J85KT6QPX|         tree hugger|sturdy but too he...|    1357776000|\n",
      "|5a13229a741a2384e...|B0007YXRTA|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|I have worn this ...|01 10, 2014|A1IHU2EHU673HE|     Maryanna Foster| Loving my new bra's|    1389312000|\n",
      "|5a132296741a2384e...|B0002M9DQS|Clothing_Shoes_an...|  0.0| [0, 0]|    2.0|I run in 9.5 Asic...|01 10, 2014|A1ZCGBAOW0OC7R|               Ack44|Didn't work for m...|    1389312000|\n",
      "|5a132299741a2384e...|B0007MG03M|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|We ordered the Wa...|01 10, 2014|  AYL3IMY560GR|            Joan Lee|Excited about our...|    1389312000|\n",
      "|5a132299741a2384e...|B0007L44CC|Clothing_Shoes_an...|  1.0| [1, 1]|    5.0|I have owned my C...|01 11, 2007|A117RNBA4YM5Z9|              Skully|Citizen Eco-Drive...|    1168473600|\n",
      "|5a132294741a2384e...|B0000AS4S8|Clothing_Shoes_an...|  1.0| [1, 1]|    4.0|This was a gift a...|01 11, 2007|A24H2MZ0QMK595|   Abelina M. Corder|Very nice for the...|    1168473600|\n",
      "|5a132294741a2384e...|B0000AOXKJ|Clothing_Shoes_an...|  1.0| [2, 2]|    5.0|Gave these very p...|01 11, 2007| ABRZR68B3GVUR|          T. Skinner|           Beautiful|    1168473600|\n",
      "|5a132294741a2384e...|B0000AUYUZ|Clothing_Shoes_an...|  1.0| [4, 4]|    5.0|This is the secon...|01 11, 2011|A1X8ORE50J0QZO|Lorraine Curtis \"...|             stylish|    1294704000|\n",
      "|5a132297741a2384e...|B0002QTQA2|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|These boots fit g...|01 11, 2013|A1QF0ZLOAS8LII|              mpac89|     excellent boots|    1357862400|\n",
      "|5a132299741a2384e...|B0007MG03M|Clothing_Shoes_an...|  1.0| [0, 0]|    4.0|The seams along t...|01 11, 2013|A27KWOU40GOYG3|          forealisme|A couple of probl...|    1357862400|\n",
      "|5a132299741a2384e...|B0007M6DP2|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Bought these back...|01 11, 2013|A2MNBCNDIRSCYB|           jmsbond76|    Love these shoes|    1357862400|\n",
      "|5a132296741a2384e...|B0002C81BQ|Clothing_Shoes_an...|  1.0| [1, 1]|    5.0|I had always assu...|01 12, 2007| A6CVO2D493P3V|   Barbara L. Stacey|Beautiful Freshwa...|    1168560000|\n",
      "|5a132294741a2384e...|B0000VIGLO|Clothing_Shoes_an...|  1.0| [3, 3]|    4.0|For what I paid, ...|01 12, 2008|A2W9C84H8B2BI8|        Amazon Woman|                Fine|    1200096000|\n",
      "|5a13229c741a2384e...|B0009OP1OW|Clothing_Shoes_an...|  1.0| [0, 0]|    5.0|Way worth the mon...|01 12, 2009| APOK63WCDK5L5|A. Vaughan \"free ...|            good buy|    1231718400|\n",
      "+--------------------+----------+--------------------+-----+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Remover caracteres especiais da coluna 'id'\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "\n",
    "cleaned_df = df.withColumn(\"_id\", col(\"_id\").getField(\"$oid\"))\n",
    "cleaned_df = cleaned_df.withColumn(\"_id\", regexp_replace(col(\"_id\"), \"[{}]\", \"\"))\n",
    "\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:============================================>           (19 + 5) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+-------+--------------------+-----------+--------------------+--------------+\n",
      "|                 _id|class|helpful|overall|          reviewText| reviewTime|             summary|unixReviewTime|\n",
      "+--------------------+-----+-------+-------+--------------------+-----------+--------------------+--------------+\n",
      "|5a13229b741a2384e...|  1.0| [0, 0]|    4.0|Lee straight leg,...| 01 1, 2014|     Excellent Jeans|    1388534400|\n",
      "|5a132298741a2384e...|  1.0| [0, 0]|    4.0|Fits 3x. After wa...| 01 1, 2014|liked them. order...|    1388534400|\n",
      "|5a132296741a2384e...|  1.0| [1, 1]|    4.0|The quality/workm...|01 10, 2007|     Garnet Necklace|    1168387200|\n",
      "|5a132298741a2384e...|  1.0| [0, 0]|    5.0|These are perfect...|01 10, 2013|Perfect comfy fit...|    1357776000|\n",
      "|5a132294741a2384e...|  1.0| [0, 1]|    5.0|I bought two of t...|01 10, 2013|A Perfect First W...|    1357776000|\n",
      "|5a132296741a2384e...|  1.0| [2, 2]|    5.0|I had this watch ...|01 10, 2013|Excelent watch fo...|    1357776000|\n",
      "|5a132296741a2384e...|  0.0| [0, 0]|    3.0|I bought these be...|01 10, 2013|sturdy but too he...|    1357776000|\n",
      "|5a13229a741a2384e...|  1.0| [0, 0]|    5.0|I have worn this ...|01 10, 2014| Loving my new bra's|    1389312000|\n",
      "|5a132296741a2384e...|  0.0| [0, 0]|    2.0|I run in 9.5 Asic...|01 10, 2014|Didn't work for m...|    1389312000|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|    5.0|We ordered the Wa...|01 10, 2014|Excited about our...|    1389312000|\n",
      "|5a132299741a2384e...|  1.0| [1, 1]|    5.0|I have owned my C...|01 11, 2007|Citizen Eco-Drive...|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [1, 1]|    4.0|This was a gift a...|01 11, 2007|Very nice for the...|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [2, 2]|    5.0|Gave these very p...|01 11, 2007|           Beautiful|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [4, 4]|    5.0|This is the secon...|01 11, 2011|             stylish|    1294704000|\n",
      "|5a132297741a2384e...|  1.0| [0, 0]|    5.0|These boots fit g...|01 11, 2013|     excellent boots|    1357862400|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|    4.0|The seams along t...|01 11, 2013|A couple of probl...|    1357862400|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|    5.0|Bought these back...|01 11, 2013|    Love these shoes|    1357862400|\n",
      "|5a132296741a2384e...|  1.0| [1, 1]|    5.0|I had always assu...|01 12, 2007|Beautiful Freshwa...|    1168560000|\n",
      "|5a132294741a2384e...|  1.0| [3, 3]|    4.0|For what I paid, ...|01 12, 2008|                Fine|    1200096000|\n",
      "|5a13229c741a2384e...|  1.0| [0, 0]|    5.0|Way worth the mon...|01 12, 2009|            good buy|    1231718400|\n",
      "+--------------------+-----+-------+-------+--------------------+-----------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remover colunas que não são necessárias para o problema em questão\n",
    "cleaned_df = cleaned_df.drop( 'category', 'asin' , 'reviewerID', 'reviewerName') \n",
    "\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear as colunas 'overall' e '-id' \n",
    "cleaned_df = cleaned_df.withColumnRenamed(\"overall\", \"productRating\")\\\n",
    "            .withColumnRenamed(\"_id\", \"id\")\n",
    "            \n",
    "            \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+-------------+--------------------+-----------+--------------------+--------------+\n",
      "|                  id|class|helpful|productRating|          reviewText| reviewTime|             summary|unixReviewTime|\n",
      "+--------------------+-----+-------+-------------+--------------------+-----------+--------------------+--------------+\n",
      "|5a13229b741a2384e...|  1.0| [0, 0]|          4.0|Lee straight leg,...| 01 1, 2014|     Excellent Jeans|    1388534400|\n",
      "|5a132298741a2384e...|  1.0| [0, 0]|          4.0|Fits 3x. After wa...| 01 1, 2014|liked them. order...|    1388534400|\n",
      "|5a132296741a2384e...|  1.0| [1, 1]|          4.0|The quality/workm...|01 10, 2007|     Garnet Necklace|    1168387200|\n",
      "|5a132298741a2384e...|  1.0| [0, 0]|          5.0|These are perfect...|01 10, 2013|Perfect comfy fit...|    1357776000|\n",
      "|5a132294741a2384e...|  1.0| [0, 1]|          5.0|I bought two of t...|01 10, 2013|A Perfect First W...|    1357776000|\n",
      "|5a132296741a2384e...|  1.0| [2, 2]|          5.0|I had this watch ...|01 10, 2013|Excelent watch fo...|    1357776000|\n",
      "|5a132296741a2384e...|  0.0| [0, 0]|          3.0|I bought these be...|01 10, 2013|sturdy but too he...|    1357776000|\n",
      "|5a13229a741a2384e...|  1.0| [0, 0]|          5.0|I have worn this ...|01 10, 2014| Loving my new bra's|    1389312000|\n",
      "|5a132296741a2384e...|  0.0| [0, 0]|          2.0|I run in 9.5 Asic...|01 10, 2014|Didn't work for m...|    1389312000|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|          5.0|We ordered the Wa...|01 10, 2014|Excited about our...|    1389312000|\n",
      "|5a132299741a2384e...|  1.0| [1, 1]|          5.0|I have owned my C...|01 11, 2007|Citizen Eco-Drive...|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [1, 1]|          4.0|This was a gift a...|01 11, 2007|Very nice for the...|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [2, 2]|          5.0|Gave these very p...|01 11, 2007|           Beautiful|    1168473600|\n",
      "|5a132294741a2384e...|  1.0| [4, 4]|          5.0|This is the secon...|01 11, 2011|             stylish|    1294704000|\n",
      "|5a132297741a2384e...|  1.0| [0, 0]|          5.0|These boots fit g...|01 11, 2013|     excellent boots|    1357862400|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|          4.0|The seams along t...|01 11, 2013|A couple of probl...|    1357862400|\n",
      "|5a132299741a2384e...|  1.0| [0, 0]|          5.0|Bought these back...|01 11, 2013|    Love these shoes|    1357862400|\n",
      "|5a132296741a2384e...|  1.0| [1, 1]|          5.0|I had always assu...|01 12, 2007|Beautiful Freshwa...|    1168560000|\n",
      "|5a132294741a2384e...|  1.0| [3, 3]|          4.0|For what I paid, ...|01 12, 2008|                Fine|    1200096000|\n",
      "|5a13229c741a2384e...|  1.0| [0, 0]|          5.0|Way worth the mon...|01 12, 2009|            good buy|    1231718400|\n",
      "+--------------------+-----+-------+-------------+--------------------+-----------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing the number of votes received as a metric from Helpful\n",
    "cleaned_df = cleaned_df.withColumn('reviewUpvotes', col('helpful')[0])\n",
    "# cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the originally 'helpful' column to a float value showcasing No. of people who found it helpful among the total people that viewed it\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def helpful_ratio(helpful):\n",
    "    try:\n",
    "        return (helpful[0] / helpful[1])*100\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0  # or any other value that makes sense in the context\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# UDF registration\n",
    "ratio_udf = udf(helpful_ratio, FloatType())\n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "cleaned_df =  cleaned_df.withColumn('helpful', ratio_udf(col('helpful')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df =cleaned_df.withColumnRenamed(\"helpful\", \"helpfulTotalRatio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'class',\n",
       " 'helpfulTotalRatio',\n",
       " 'productRating',\n",
       " 'reviewText',\n",
       " 'reviewTime',\n",
       " 'summary',\n",
       " 'unixReviewTime',\n",
       " 'reviewUpvotes']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "|                  id|class|helpfulTotalRatio|productRating|          reviewText|reviewTime|             summary|unixReviewTime|reviewUpvotes|\n",
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "|5a13229b741a2384e...|  1.0|              0.0|          4.0|Lee straight leg,...|      NULL|     Excellent Jeans|    1388534400|            0|\n",
      "|5a132298741a2384e...|  1.0|              0.0|          4.0|Fits 3x. After wa...|      NULL|liked them. order...|    1388534400|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          4.0|The quality/workm...|      NULL|     Garnet Necklace|    1168387200|            1|\n",
      "|5a132298741a2384e...|  1.0|              0.0|          5.0|These are perfect...|      NULL|Perfect comfy fit...|    1357776000|            0|\n",
      "|5a132294741a2384e...|  1.0|              0.0|          5.0|I bought two of t...|      NULL|A Perfect First W...|    1357776000|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          5.0|I had this watch ...|      NULL|Excelent watch fo...|    1357776000|            2|\n",
      "|5a132296741a2384e...|  0.0|              0.0|          3.0|I bought these be...|      NULL|sturdy but too he...|    1357776000|            0|\n",
      "|5a13229a741a2384e...|  1.0|              0.0|          5.0|I have worn this ...|      NULL| Loving my new bra's|    1389312000|            0|\n",
      "|5a132296741a2384e...|  0.0|              0.0|          2.0|I run in 9.5 Asic...|      NULL|Didn't work for m...|    1389312000|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          5.0|We ordered the Wa...|      NULL|Excited about our...|    1389312000|            0|\n",
      "|5a132299741a2384e...|  1.0|            100.0|          5.0|I have owned my C...|      NULL|Citizen Eco-Drive...|    1168473600|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          4.0|This was a gift a...|      NULL|Very nice for the...|    1168473600|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          5.0|Gave these very p...|      NULL|           Beautiful|    1168473600|            2|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          5.0|This is the secon...|      NULL|             stylish|    1294704000|            4|\n",
      "|5a132297741a2384e...|  1.0|              0.0|          5.0|These boots fit g...|      NULL|     excellent boots|    1357862400|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          4.0|The seams along t...|      NULL|A couple of probl...|    1357862400|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          5.0|Bought these back...|      NULL|    Love these shoes|    1357862400|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          5.0|I had always assu...|      NULL|Beautiful Freshwa...|    1168560000|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          4.0|For what I paid, ...|      NULL|                Fine|    1200096000|            3|\n",
      "|5a13229c741a2384e...|  1.0|              0.0|          5.0|Way worth the mon...|      NULL|            good buy|    1231718400|            0|\n",
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Converter a coluna 'reviewTime' para o formato timestamp, assumindo que a data esteja no formato MM/dd/yyyy\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "cleaned_df = cleaned_df .withColumn(\"reviewTime\", to_timestamp(\"reviewTime\", \"MM/dd/yyyy\"))\n",
    "cleaned_df .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 reviewText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+--------------+-------------+\n",
      "|id                      |class|helpfulTotalRatio|productRating|reviewText                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |reviewTime|summary                                 |unixReviewTime|reviewUpvotes|\n",
      "+------------------------+-----+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+--------------+-------------+\n",
      "|5a13229b741a2384e83a658b|1.0  |0.0              |4.0          |lee straight leg double black jeans are well made and good looking the fit is comfortable but not baggy i have washed these jeans several times and the double black process slows down the fading so common in black jeans                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL      |Excellent Jeans                         |1388534400    |0            |\n",
      "|5a132298741a2384e83985ee|1.0  |0.0              |4.0          |fits x after washing seems just a tad too short when i lift my arms but i believe its because i should have ordered big and tall good quality and color                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |NULL      |liked them. ordered few different colors|1388534400    |0            |\n",
      "|5a132296741a2384e8387de9|1.0  |100.0            |4.0          |the quality workmanship of the necklace is very good i bought this for my daughter s birthday she likes the looks of the necklace off but has never worn it because it doesn t lay just right on when it is around her neck                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL      |Garnet Necklace                         |1168387200    |1            |\n",
      "|5a132298741a2384e83940c9|1.0  |0.0              |5.0          |these are perfect trousers in my opinion the material is supple heavy enough to be good quality but not too thick that they don t breathe so to speak i am and the length is just right they come up to a comfortable place on my middle they are just what i was looking for                                                                                                                                                                                                                                                                                                                                                                                                         |NULL      |Perfect comfy fitness trousers          |1357776000    |0            |\n",
      "|5a132294741a2384e837dabf|1.0  |0.0              |5.0          |i bought two of this type of watch last year and they worked wonderfully both grand kids learned to tell time i have a year old grandson that requested one this year since he s already picked up the fundamentals of time telling he loves it the elastic band adjusts down in size so there s no worry of it falling off the colors are vibrant and the lizards were a big hit a perfect first watch                                                                                                                                                                                                                                                                               |NULL      |A Perfect First Watch                   |1357776000    |0            |\n",
      "|5a132296741a2384e8386f9b|1.0  |100.0            |5.0          |i had this watch for the last years went swimming snorkeling and even scooba diving with it it never failed glow is definitely a plus excellent not expensive choice note description seems to have a typo wr is m not ft which is much better                                                                                                                                                                                                                                                                                                                                                                                                                                        |NULL      |Excelent watch for the price.           |1357776000    |2            |\n",
      "|5a132296741a2384e83897a1|0.0  |0.0              |3.0          |i bought these because i wanted a better tread on my boot the other muck boots i have are too slippery in the mud these boots are really well made with a good sole but very stiff and not cushy like my other pair they are also fairly heavy i need a boot that isn t this heavy but has a good tread any suggestions                                                                                                                                                                                                                                                                                                                                                               |NULL      |sturdy but too heavy for me             |1357776000    |0            |\n",
      "|5a13229a741a2384e83a3827|1.0  |0.0              |5.0          |i have worn this bra for many years the last two times i needed new one s i ordered from amazon couldn t be happier same as the expensive one i have bought for years the fit well and the lift is very good and i got new ones for price thank you for your quick and easy service pleased in alabama roll tide                                                                                                                                                                                                                                                                                                                                                                      |NULL      |Loving my new bra's                     |1389312000    |0            |\n",
      "|5a132296741a2384e838bb45|0.0  |0.0              |2.0          |i run in asics womens tried the small but they didn t fit my shoe got the medium and the heel piece still didn t sit flush against the sole of my shoe but i tried running in them anyway i was very confident running on the slippery sidewalks of my neighborhood which was awesome i have fallen a number of times running with yaktrax but the deal breaker for me is that the toe piece pushes right against my bone spur ok it s bunion i just hate saying that word i wasn t crazy about the added weight of these compared to yaktrax but the sure footed ness of them would make up for that in my opinion plus you would just be faster in the spring when you take them off|NULL      |Didn't work for me :-(                  |1389312000    |0            |\n",
      "|5a132299741a2384e839b9ca|1.0  |0.0              |5.0          |we ordered the wallabee boot for our son he loved the boot it fit like a glove the sand color was very well chosen because it would go with all of his clothes they fit nice round his angle and was very comfortable we plan to order from amazon again soon                                                                                                                                                                                                                                                                                                                                                                                                                         |NULL      |Excited about our Purchase!             |1389312000    |0            |\n",
      "|5a132299741a2384e839a535|1.0  |100.0            |5.0          |i have owned my citizen eco drive diver s watch for over years and love it but the band was pretty worn out this band is a little more expensive than your usual replacement band but it is pretty much an exact match to the original band i plan to get another years out of the watch now i would recommend it you want an exact replacement                                                                                                                                                                                                                                                                                                                                       |NULL      |Citizen Eco-Drive Exact Replacement Band|1168473600    |1            |\n",
      "|5a132294741a2384e837c1f4|1.0  |100.0            |4.0          |this was a gift and i was not sure of the quality when i ordered but when i saw it i was impressed very nice for a reasonable price                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |NULL      |Very nice for the price                 |1168473600    |1            |\n",
      "|5a132294741a2384e837c127|1.0  |100.0            |5.0          |gave these very pretty earrings to my sister for christmas she loved them too                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |NULL      |Beautiful                               |1168473600    |2            |\n",
      "|5a132294741a2384e837cd0f|1.0  |100.0            |5.0          |this is the second of these i have purchased for my husband it is first of all not a cowboy hat but a very stylish panama like hat the crown is very well ventilated and the brim is lined to provide excellent shade to the face                                                                                                                                                                                                                                                                                                                                                                                                                                                     |NULL      |stylish                                 |1294704000    |4            |\n",
      "|5a132297741a2384e838cd56|1.0  |0.0              |5.0          |these boots fit great my feet don t slide around inside the boot like they do with uggs and the price made my day                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |NULL      |excellent boots                         |1357862400    |0            |\n",
      "|5a132299741a2384e839b98b|1.0  |0.0              |4.0          |the seams along the sides started coming undone after wearing them twice amazon took care of me and sent me a new pair at no cost they even paid for the return shipping must have been a fluke during manufacturing because i ve problems with the new pair i m happy                                                                                                                                                                                                                                                                                                                                                                                                                |NULL      |A couple of problems...                 |1357862400    |0            |\n",
      "|5a132299741a2384e839ae06|1.0  |0.0              |5.0          |bought these back in and still have them in rotation they have been amazingly durable and comfortable i would recommend                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |NULL      |Love these shoes                        |1357862400    |0            |\n",
      "|5a132296741a2384e83899b1|1.0  |100.0            |5.0          |i had always assumed that freshwater pearls were oddly shaped and not as attractive as their saltwater cousins this set put my assumptions to rest it is a beautiful set of pearls at a very competetive price                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |NULL      |Beautiful Freshwater Pearls             |1168560000    |1            |\n",
      "|5a132294741a2384e838104e|1.0  |100.0            |4.0          |for what i paid it was exactly what i asked for i am very satisfied with the order it even came earlier than i was expecting it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |NULL      |Fine                                    |1200096000    |3            |\n",
      "|5a13229c741a2384e83ac749|1.0  |0.0              |5.0          |way worth the moneyit was a gift and my dad loves it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL      |good buy                                |1231718400    |0            |\n",
      "+------------------------+-----+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Converter todos os caracteres para minúsculas\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.lower(cleaned_df['reviewText']))\n",
    "\n",
    "# Remover código HTML\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '<[^>]+>', ''))\n",
    "\n",
    "# Remover URLs\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], 'http\\S+|www\\S+|https?\\:\\/\\/\\S+', ''))\n",
    "\n",
    "# Remover menções a usuários (não é comum em reviews da Amazon)\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '@\\w+', ''))\n",
    "\n",
    "# Remover hashtags (não é comum em reviews da Amazon)\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '#\\w+', ''))\n",
    "\n",
    "# Remover entidades HTML (&amp;, &lt;, etc.)\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '&\\w+;', ''))\n",
    "\n",
    "# Substituir caracteres não alfanuméricos e pontuação por um espaço em branco\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '[^\\w\\s]', ' '))\n",
    "\n",
    "# Remover números (avaliações numéricas, preços, etc.)\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\d+', ''))\n",
    "\n",
    "# Substituir dígitos por um espaço em branco\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\d', ' '))\n",
    "\n",
    "# Remover espaços múltiplos e linhas novas\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\s+', ' '))\n",
    "\n",
    "# Remover espaços no início e no fim\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.trim(cleaned_df['reviewText']))\n",
    "\n",
    "# cleaned_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "|                  id|class|helpfulTotalRatio|productRating|          reviewText|reviewTime|             summary|unixReviewTime|reviewUpvotes|\n",
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "|5a13229b741a2384e...|  1.0|              0.0|          4.0|lee straight leg ...|      NULL|     excellent jeans|    1388534400|            0|\n",
      "|5a132298741a2384e...|  1.0|              0.0|          4.0|fits x after wash...|      NULL|liked them ordere...|    1388534400|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          4.0|the quality workm...|      NULL|     garnet necklace|    1168387200|            1|\n",
      "|5a132298741a2384e...|  1.0|              0.0|          5.0|these are perfect...|      NULL|perfect comfy fit...|    1357776000|            0|\n",
      "|5a132294741a2384e...|  1.0|              0.0|          5.0|i bought two of t...|      NULL|a perfect first w...|    1357776000|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          5.0|i had this watch ...|      NULL|excelent watch fo...|    1357776000|            2|\n",
      "|5a132296741a2384e...|  0.0|              0.0|          3.0|i bought these be...|      NULL|sturdy but too he...|    1357776000|            0|\n",
      "|5a13229a741a2384e...|  1.0|              0.0|          5.0|i have worn this ...|      NULL|  loving my new bras|    1389312000|            0|\n",
      "|5a132296741a2384e...|  0.0|              0.0|          2.0|i run in asics wo...|      NULL|  didnt work for me |    1389312000|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          5.0|we ordered the wa...|      NULL|excited about our...|    1389312000|            0|\n",
      "|5a132299741a2384e...|  1.0|            100.0|          5.0|i have owned my c...|      NULL|citizen ecodrive ...|    1168473600|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          4.0|this was a gift a...|      NULL|very nice for the...|    1168473600|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          5.0|gave these very p...|      NULL|           beautiful|    1168473600|            2|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          5.0|this is the secon...|      NULL|             stylish|    1294704000|            4|\n",
      "|5a132297741a2384e...|  1.0|              0.0|          5.0|these boots fit g...|      NULL|     excellent boots|    1357862400|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          4.0|the seams along t...|      NULL|a couple of problems|    1357862400|            0|\n",
      "|5a132299741a2384e...|  1.0|              0.0|          5.0|bought these back...|      NULL|    love these shoes|    1357862400|            0|\n",
      "|5a132296741a2384e...|  1.0|            100.0|          5.0|i had always assu...|      NULL|beautiful freshwa...|    1168560000|            1|\n",
      "|5a132294741a2384e...|  1.0|            100.0|          4.0|for what i paid i...|      NULL|                fine|    1200096000|            3|\n",
      "|5a13229c741a2384e...|  1.0|              0.0|          5.0|way worth the mon...|      NULL|            good buy|    1231718400|            0|\n",
      "+--------------------+-----+-----------------+-------------+--------------------+----------+--------------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace\n",
    "cleaned_df = cleaned_df.withColumn(\"summary\", lower(col(\"summary\")))\\\n",
    "                 .withColumn(\"summary\", regexp_replace(col(\"summary\"), \"[^\\w\\s]\", \"\"))\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construção do modelo com Algoritmos de Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo 1: Regressão Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|class| count|\n",
      "+-----+------+\n",
      "|  0.0|117052|\n",
      "|  1.0|433077|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum class count: 117052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|  0.0|93757|\n",
      "|  1.0|93488|\n",
      "+-----+-----+\n",
      "\n",
      "Número de linhas após amostragem: 187245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/02 15:59:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:25 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:28 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:28 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:28 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:28 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:30 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:31 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:32 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:35 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:36 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:37 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:38 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/02 15:59:39 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "/Users/nuno/.local/lib/python3.9/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "24/06/02 15:59:40 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/02 15:59:41 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1.0:\n",
      "  Precision = 0.80\n",
      "  Recall = 0.80\n",
      "  F1 Score = 0.80\n",
      "Class 0.0:\n",
      "  Precision = 0.80\n",
      "  Recall = 0.80\n",
      "  F1 Score = 0.80\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import to_timestamp, col, regexp_replace\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "# Create Spark session with increased memory settings\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LogisticRegressionExample\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"512m\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.memoryOverhead\", \"512m\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Assuming your data is in a JSON file and has columns 'reviewText' and 'class'\n",
    "file_path = \"Clothing_Shoes_and_Jewelry.json\"\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.json(file_path)\n",
    "\n",
    "df = df.sample(fraction=0.1, seed=12345)\n",
    "\n",
    "\n",
    "# Clean and preprocess the data\n",
    "cleaned_df = df.withColumn(\"_id\", col(\"_id\").getField(\"$oid\"))\n",
    "cleaned_df = cleaned_df.withColumn(\"_id\", regexp_replace(col(\"_id\"), \"[{}]\", \"\"))\n",
    "cleaned_df = cleaned_df.withColumnRenamed(\"overall\", \"productRating\")\\\n",
    "                       .withColumnRenamed(\"_id\", \"id\")\\\n",
    "                       .drop('category', 'asin', 'reviewerID', 'reviewerName')\\\n",
    "                       .withColumn('reviewUpvotes', col('helpful')[0])\\\n",
    "                       .withColumn(\"reviewTime\", to_timestamp(\"reviewTime\", \"MM/dd/yyyy\"))\n",
    "\n",
    "# Further text cleaning\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.lower(cleaned_df['reviewText']))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '<[^>]+>', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], 'http\\S+|www\\S+|https?\\:\\/\\/\\S+', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '@\\w+', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '#\\w+', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '&\\w+;', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '[^\\w\\s]', ' '))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\d+', ''))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\d', ' '))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.regexp_replace(cleaned_df['reviewText'], '\\s+', ' '))\n",
    "cleaned_df = cleaned_df.withColumn('reviewText', F.trim(cleaned_df['reviewText']))\n",
    "\n",
    "# Checking for class imbalance\n",
    "class_distribution = cleaned_df.groupBy(\"class\").count().orderBy(\"class\")\n",
    "class_distribution.show()\n",
    "\n",
    "# Undersample the majority class\n",
    "min_class_count = class_distribution.agg({\"count\": \"min\"}).collect()[0][0]\n",
    "\n",
    "print(\"Minimum class count:\", min_class_count)\n",
    "\n",
    "undersampled_df = cleaned_df.groupBy(\"class\").applyInPandas(\n",
    "    lambda pdf: pdf.sample(n=min_class_count, random_state=42) if len(pdf) > min_class_count else pdf,\n",
    "    schema=cleaned_df.schema\n",
    ")\n",
    "\n",
    "\n",
    "# Pre-processing stages\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered_tokens\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"class\")\n",
    "\n",
    "# Pipeline construction\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])\n",
    "\n",
    "# Persist DataFrame to disk to save memory\n",
    "undersampled_df.persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = undersampled_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "count_classes = train_df.groupBy(\"class\").count().orderBy(\"class\")\n",
    "count_classes.show()\n",
    "\n",
    "# Verificando\n",
    "print(\"Número de linhas após amostragem:\", train_df.count())\n",
    "\n",
    "\n",
    "# Train the model using the training data\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Calculate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy:.2f}\")\n",
    "\n",
    "# Calculate other metrics\n",
    "predictionAndLabels = predictions.select(\"prediction\", \"class\").rdd.map(lambda row: (row[0], row[1]))\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "labels = predictions.select(\"class\").distinct().collect()\n",
    "labels = [row['class'] for row in labels]\n",
    "\n",
    "for label in labels:\n",
    "    precision = metrics.precision(label)\n",
    "    recall = metrics.recall(label)\n",
    "    f1Score = metrics.fMeasure(label)\n",
    "    print(f\"Class {label}:\")\n",
    "    print(f\"  Precision = {precision:.2f}\")\n",
    "    print(f\"  Recall = {recall:.2f}\")\n",
    "    print(f\"  F1 Score = {f1Score:.2f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "* Descrever brevemente o objetivo do notebook.\n",
    "\n",
    "# Limpeza de Dados\n",
    "\n",
    "* Renomear colunas para melhor legibilidade.\n",
    "* Converter textos para minúsculas e remover pontuações.\n",
    "* Remover caracteres especiais de IDs e outras colunas.\n",
    "* Transformar colunas em dados úteis, tais como `reviewTime`.\n",
    "\n",
    "# Análise Exploratória de Dados (EDA)\n",
    "\n",
    "* Criar histogramas:\n",
    "    * **Distribuição de tamanhos das reviews**:\n",
    "        * **Insight**: A maioria das reviews são curtas ou longas? Como isso pode influenciar a perceção dos produtos?\n",
    "    * **Distribuição de avaliações (e.g., estrelas)**:\n",
    "        * **Insight**: Qual é a distribuição das classificações? Há uma predominância de avaliações positivas ou negativas?\n",
    "    * **Distribuição por categorias ou produtos, se aplicável**:\n",
    "        * **Insight**: Quais categorias ou produtos recebem mais reviews? Existem produtos com avaliações consistentemente mais altas ou baixas?\n",
    "\n",
    "* Análise adicional:\n",
    "    * **Analisar a correlação entre o tamanho da review e a avaliação dada**:\n",
    "        * **Insight**: Reviews mais longas tendem a ser mais críticas ou elogiosas?\n",
    "    * **Analisar as reviews mais comuns** (e.g., palavras mais frequentes em reviews positivas vs. negativas).\n",
    "\n",
    "# Pré-processamento de Texto\n",
    "\n",
    "* Tokenizar os textos das reviews.\n",
    "* Remover palavras irrelevantes (stop words).\n",
    "* Negação, Stem e Lemmatização.\n",
    "* Converter tokens em features utilizando técnicas como TF-IDF.\n",
    "\n",
    "# Treinamento de Modelos\n",
    "\n",
    "* Treinar diferentes modelos de classificação (e.g., Logistic Regression, Decision Tree, Random Forest, Gradient Boosted Trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Por questões de produtividade, devem ser considerados dois conjuntos de dados aquando do desenvolvimento da solução. Assim, para além dos dados originais na sua integra, deve ser utilizado um conjunto de dados de menor dimensão (sub-conjunto dos anteriores), para o caso de tarefas intensivas e frequentes, inerentes ao próprio processo de desenvolvimento da solução.\n",
    "\n",
    "• Cada notebook (ou módulo) deverá ser autónomo em termos de fontes de dados. Sugere se que estruturem o código por forma a ler e gravar os dados entre cada uma das etapas do projeto. Isto é particularmente importante para a parte da visualização: a geração\n",
    "de um gráfico ou tabela não deverá implicar a realização da simulação/processamento no mesmo instante. Preferencialmente deverá importar os dados já processados a partir de ficheiros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliografia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/naveedhn/amazon-product-review-spam-and-non-spam/data?select=Clothing_Shoes_and_Jewelry     https://ieeexplore.ieee.org/abstract/document/9027828"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
